<story-context id="bmad/bmm/workflows/4-implementation/story-context/template" v="1.0">
  <metadata>
    <epicId>1</epicId>
    <storyId>1.1</storyId>
    <title>Response Detail Levels</title>
    <status>Ready</status>
    <generatedAt>2025-10-18</generatedAt>
    <generator>BMAD Story Context Workflow</generator>
    <sourceStoryPath>docs/stories/story-1.1.md</sourceStoryPath>
  </metadata>

  <story>
    <asA>TeachFlow agent</asA>
    <iWant>configurable response detail levels</iWant>
    <soThat>I can minimize token usage for bulk operations while maintaining access to full details when needed</soThat>
    <tasks>
      <task id="1" ac="1,2">Add `detail_level` parameter to all 5 MCP tool schemas with Zod validation</task>
      <task id="2" ac="3,4,5">Create response-formatter.ts module with minimal/summary/full mode formatters</task>
      <task id="3" ac="1,2,3,4,5">Integrate formatter into all 5 tool handlers</task>
      <task id="4" ac="6">Add token counting instrumentation with chars/4 approximation</task>
      <task id="5" ac="1-7">Create unit tests for all detail levels and validation</task>
      <task id="6" ac="7">Validate 85-90% token reduction target via benchmark script</task>
    </tasks>
  </story>

  <acceptanceCriteria>
    <criterion id="1">Add `detail_level` parameter to all 5 MCP tools (`minimal`, `summary`, `full`)</criterion>
    <criterion id="2">Default behavior unchanged (`full` mode) for backward compatibility</criterion>
    <criterion id="3">`minimal` mode: code, topic, truncated PE (50 chars)</criterion>
    <criterion id="4">`summary` mode: code, topic, PE (150 chars), top 3 keywords</criterion>
    <criterion id="5">`full` mode: complete standard object (current behavior)</criterion>
    <criterion id="6">Token counting instrumentation added to all responses</criterion>
    <criterion id="7">Validation: `summary` mode achieves 85-90% token reduction vs `full`</criterion>
  </acceptanceCriteria>

  <artifacts>
    <docs>
      <doc>
        <path>docs/PRD.md</path>
        <title>NGSS-MCP Optimization Product Requirements Document</title>
        <section>FR-1: Response Size Optimization</section>
        <snippet>FR-1.1: Add configurable detail levels: `minimal`, `summary`, `full`. FR-1.2: Default to `summary` mode (PE truncated, keywords limited). Success metric: 95% token reduction (2-3KB â†’ 300-500 bytes per lookup).</snippet>
      </doc>
      <doc>
        <path>docs/Epics.md</path>
        <title>Epic Breakdown - E1-S1: Response Detail Levels</title>
        <section>E1: Token Efficiency & Response Optimization</section>
        <snippet>Primary goal: Enable TeachFlow agents to perform 10x more lookups within same token budget. Implementation: Create centralized response-formatter.ts module. Token approximation: chars/4. Target: 85-90% reduction validated.</snippet>
      </doc>
      <doc>
        <path>README.md</path>
        <title>NGSS MCP Server Documentation</title>
        <section>Available Tools</section>
        <snippet>5 MCP tools: get_standard, search_by_domain, find_by_driving_question, get_3d_components, search_standards. All currently return complete standard objects (~2-3KB each).</snippet>
      </doc>
    </docs>

    <code>
      <artifact>
        <path>src/server/index.ts</path>
        <kind>MCP server entry point</kind>
        <symbol>registerTool() calls for all 5 tools</symbol>
        <lines>40-200+</lines>
        <reason>All 5 tool schemas must be updated to accept detail_level parameter with Zod validation. Tool handlers must integrate formatResponse() before returning results.</reason>
      </artifact>
      <artifact>
        <path>src/server/database.ts</path>
        <kind>Database query layer</kind>
        <symbol>getStandardByCode(), searchByDomain(), findByDrivingQuestion(), get3DComponents(), searchStandards()</symbol>
        <lines>full file</lines>
        <reason>Current query methods return complete standard objects. May need to pass detail_level through for future optimization, but initial implementation will format at tool handler level.</reason>
      </artifact>
      <artifact>
        <path>src/types/ngss.ts</path>
        <kind>Type definitions</kind>
        <symbol>Standard interface and related types</symbol>
        <lines>full file</lines>
        <reason>Add DetailLevel type: "minimal" | "summary" | "full". May need response format types for each detail level (optional: use discriminated unions).</reason>
      </artifact>
      <artifact>
        <path>src/server/query-validation.ts</path>
        <kind>Input validation utilities</kind>
        <symbol>QueryValidator class</symbol>
        <lines>full file</lines>
        <reason>Reference for validation patterns. New detail_level parameter validation should follow existing Zod schema patterns.</reason>
      </artifact>
    </code>

    <dependencies>
      <node>
        <dependency name="@modelcontextprotocol/sdk" version="^1.20.0">MCP server framework - use for tool registration and schema definition</dependency>
        <dependency name="zod" version="^3.25.76">Schema validation - use for detail_level parameter validation</dependency>
        <dependency name="fast-levenshtein" version="^3.0.0">Fuzzy matching - not directly relevant to this story</dependency>
      </node>
      <devDependencies>
        <dependency name="typescript" version="^5.9.3">TypeScript compiler - strict mode compliance required</dependency>
        <dependency name="bun">Test runner - use "bun test" for running tests</dependency>
      </devDependencies>
    </dependencies>
  </artifacts>

  <constraints>
    <constraint>BACKWARD COMPATIBILITY: Default behavior must remain unchanged - detail_level defaults to "full" mode</constraint>
    <constraint>ALL PARAMETERS OPTIONAL: New detail_level parameter must be optional to avoid breaking existing integrations</constraint>
    <constraint>PURE FUNCTIONS: response-formatter.ts must use pure functions for testability</constraint>
    <constraint>WORD BOUNDARY TRUNCATION: PE text truncation must cut at word boundaries and append "..." to avoid mid-word breaks</constraint>
    <constraint>TOKEN ESTIMATION: Use characters/4 approximation for GPT tokenization estimate</constraint>
    <constraint>NO DUPLICATION: Centralize formatting logic in response-formatter.ts to avoid code duplication across 5 tool handlers</constraint>
    <constraint>TYPE SAFETY: Add DetailLevel type and update tool return types appropriately</constraint>
  </constraints>

  <interfaces>
    <interface>
      <name>formatResponse</name>
      <kind>function signature</kind>
      <signature>function formatResponse(standard: Standard, detailLevel: DetailLevel): MinimalStandard | SummaryStandard | Standard</signature>
      <path>src/server/response-formatter.ts (to be created)</path>
    </interface>
    <interface>
      <name>estimateTokens</name>
      <kind>function signature</kind>
      <signature>function estimateTokens(text: string): number</signature>
      <path>src/server/token-counter.ts (to be created)</path>
    </interface>
    <interface>
      <name>detail_level parameter</name>
      <kind>Zod schema</kind>
      <signature>z.enum(["minimal", "summary", "full"]).optional().default("full")</signature>
      <path>src/server/index.ts (to be modified)</path>
    </interface>
  </interfaces>

  <tests>
    <standards>
      Use bun as test runner ("bun test"). Follow existing test patterns in the project. Create unit tests for pure functions in response-formatter.ts. Create integration tests for all 5 MCP tools testing each detail level. Test backward compatibility (no parameter should default to full mode). Validate token reduction targets via benchmark suite.
    </standards>

    <locations>
      - src/server/__tests__/ (if following common pattern)
      - src/server/response-formatter.test.ts (unit tests)
      - Integration tests alongside src/server/index.ts
      - scripts/benchmark-tokens.ts (benchmark suite for validation)
    </locations>

    <ideas>
      <test ac="1,2">Test all 5 tools accept detail_level parameter with valid enum values</test>
      <test ac="2">Test default behavior: no detail_level parameter returns full mode response</test>
      <test ac="3">Test minimal mode returns only: code, topic, PE (50 chars truncated)</test>
      <test ac="4">Test summary mode returns: code, topic, PE (150 chars), top 3 keywords</test>
      <test ac="5">Test full mode returns complete Standard object unchanged</test>
      <test ac="1">Test invalid detail_level values are rejected by Zod validation</test>
      <test ac="6">Test token metadata is included in all responses</test>
      <test ac="7">Benchmark: measure full vs summary vs minimal token counts with real NGSS data</test>
      <test ac="7">Validation: assert summary mode achieves 85-90% reduction vs full mode</test>
    </ideas>
  </tests>
</story-context>
